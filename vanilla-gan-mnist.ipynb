{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nfrom glob import glob\nfrom collections import Counter\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchsummary import summary\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import ToTensor, Resize, Normalize\nimport torchvision \nfrom torch import optim\n\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:03.805770Z","iopub.execute_input":"2025-07-10T17:11:03.806507Z","iopub.status.idle":"2025-07-10T17:11:03.811559Z","shell.execute_reply.started":"2025-07-10T17:11:03.806481Z","shell.execute_reply":"2025-07-10T17:11:03.810711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameters and Setup ","metadata":{}},{"cell_type":"code","source":"# Hyperparameters etc\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\nLEARNING_RATE = 2e-4\nBATCH_SIZE = 64\nIMAGE_SIZE = 64\nZ_DIM = 100\nEPOCHS = 10\nROOT_DIR = \"/kaggle/working/\"\nNUM_WORKERS = 2\nIMG_DIM = 28 * 28","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:04.769986Z","iopub.execute_input":"2025-07-10T17:11:04.770698Z","iopub.status.idle":"2025-07-10T17:11:04.775423Z","shell.execute_reply.started":"2025-07-10T17:11:04.770670Z","shell.execute_reply":"2025-07-10T17:11:04.774693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define The Dataset","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5),(0.5))\n])\n\ntrain_dataset = datasets.MNIST(root = ROOT_DIR, transform=train_transform, download=True)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nprint(f\"Total number of images loaded: {len(train_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:07.529954Z","iopub.execute_input":"2025-07-10T17:11:07.530535Z","iopub.status.idle":"2025-07-10T17:11:07.621222Z","shell.execute_reply.started":"2025-07-10T17:11:07.530504Z","shell.execute_reply":"2025-07-10T17:11:07.620373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To display the images after the transforms \ndata_iter = iter(train_loader) \nimages, labels= next(data_iter)\n\n# if it was MNIST or CIFAR10 \nclasses = train_dataset.classes\nprint(classes)\n\n# Show images\nfig, axes = plt.subplots(2, 5, figsize=(10, 5))\nfor i, ax in enumerate(axes.flat):\n    img = images[i]\n    # print(f\" images before reshape {img.shape}\")\n    img = np.transpose(img.numpy(), (1, 2, 0))  # Convert (C, H, W) to (H, W, C)\n    # print(f\" images after reshape {img.shape}\")\n    # img_display = (img + 1) / 2 # if it was normalize use this to recover it \n    ax.imshow(img) # expects a numpy \n    ax.set_title(f\"Image {labels[i]}\")\n    ax.axis(\"off\")\nplt.show()\n\nprint(\"Shape of one image tensor:\", images[0].shape)\nprint(\"Shape of a group of iamges is:\", images.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:08.721049Z","iopub.execute_input":"2025-07-10T17:11:08.721354Z","iopub.status.idle":"2025-07-10T17:11:09.314219Z","shell.execute_reply.started":"2025-07-10T17:11:08.721329Z","shell.execute_reply":"2025-07-10T17:11:09.313112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create Vanilla GAN","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, noise_dim=100, img_dim=28*28):\n        super(Generator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(noise_dim, 256),\n            nn.LeakyReLU(0.2),\n\n            nn.Linear(256, 512),\n            nn.LeakyReLU(0.2),\n\n            nn.Linear(512, 1024),\n            nn.LeakyReLU(0.2),\n\n            nn.Linear(1024, img_dim),\n            nn.Tanh()  # Outputs in [-1, 1] to match normalized MNIST\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:11.250698Z","iopub.execute_input":"2025-07-10T17:11:11.251007Z","iopub.status.idle":"2025-07-10T17:11:11.258074Z","shell.execute_reply.started":"2025-07-10T17:11:11.250976Z","shell.execute_reply":"2025-07-10T17:11:11.257221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, img_dim=28*28):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(img_dim, 1024),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(0.3),# \n\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(0.3),\n\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2),\n            nn.Dropout(0.3),\n\n            nn.Linear(256, 1),\n            nn.Sigmoid()  # Outputs probability in [0, 1]\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:12.696576Z","iopub.execute_input":"2025-07-10T17:11:12.696858Z","iopub.status.idle":"2025-07-10T17:11:12.702755Z","shell.execute_reply.started":"2025-07-10T17:11:12.696836Z","shell.execute_reply":"2025-07-10T17:11:12.701833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator = Generator(noise_dim= Z_DIM, img_dim=IMG_DIM)\ndiscriminator = Discriminator(img_dim= IMG_DIM)\n\ngenerator.to(device)\ndiscriminator.to(device)\n\ncriterion = nn.BCELoss()\n\noptimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:48.495396Z","iopub.execute_input":"2025-07-10T17:11:48.495721Z","iopub.status.idle":"2025-07-10T17:11:48.532959Z","shell.execute_reply.started":"2025-07-10T17:11:48.495693Z","shell.execute_reply":"2025-07-10T17:11:48.532243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def train(generator, discriminator, dataloader, epochs = 10, noise_dim=100):\n    generator.train()\n    discriminator.train()\n    d_loss_array = [] \n    g_loss_array = [] \n\n    for epoch in range(epochs):\n        for i, (real_images, _) in enumerate(dataloader):\n            real_images = real_images.view(real_images.size(0), -1).to(device) # This flattens each image from [1, 28, 28] into [784]\n                                                                                # discriminator expects flat inputs.  \n            batch_size = real_images.size(0)\n            \n            valid = torch.ones(batch_size, 1).to(device) # used with Loss to train the discriminator\n            fake = torch.zeros(batch_size, 1).to(device) # used with Loss to train the Generator\n\n            # Train Discriminator\n            optimizer_D.zero_grad()\n            real_loss = criterion(discriminator(real_images), valid)\n            noise = torch.randn(batch_size, noise_dim).to(device) # to use wit the generator\n            fake_images = generator(noise)\n            fake_loss = criterion(discriminator(fake_images.detach()), fake) # .detach so the generator is not update here \n            d_loss = (real_loss + fake_loss) / 2\n            d_loss_array.append(d_loss.item())\n            d_loss.backward()\n            optimizer_D.step()\n\n            # Train Generator\n            optimizer_G.zero_grad()\n            noise = torch.randn(batch_size, noise_dim).to(device)\n            gen_images = generator(noise)\n            g_loss = criterion(discriminator(gen_images), valid)\n            g_loss_array.append(g_loss.item())\n            g_loss.backward()\n            optimizer_G.step()\n\n            if i % 300 == 0:\n                print(f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(dataloader)}] \" f\"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n                \n        save_generated_images(generator, epoch, device, noise_dim)\n    return g_loss_array, d_loss_array\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:50.319433Z","iopub.execute_input":"2025-07-10T17:11:50.319749Z","iopub.status.idle":"2025-07-10T17:11:50.328987Z","shell.execute_reply.started":"2025-07-10T17:11:50.319727Z","shell.execute_reply":"2025-07-10T17:11:50.327921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_generated_images(generator, epoch, device, noise_dim, num_images=16):\n    generator.eval()\n    with torch.no_grad():\n        z = torch.randn(num_images, noise_dim).to(device)\n        generated_imgs = generator(z).cpu().view(num_images, 1, 28, 28)\n        grid = torchvision.utils.make_grid(generated_imgs, nrow=4, normalize=True)\n        plt.figure(figsize=(6,6))\n        plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n        plt.title(f\"Generated Images - Epoch {epoch+1}\")\n        plt.axis('off')\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:52.065453Z","iopub.execute_input":"2025-07-10T17:11:52.066073Z","iopub.status.idle":"2025-07-10T17:11:52.072353Z","shell.execute_reply.started":"2025-07-10T17:11:52.066046Z","shell.execute_reply":"2025-07-10T17:11:52.071302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_loss, d_loss = train(generator, discriminator, train_loader, epochs=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:11:54.605449Z","iopub.execute_input":"2025-07-10T17:11:54.605748Z","iopub.status.idle":"2025-07-10T17:11:57.055049Z","shell.execute_reply.started":"2025-07-10T17:11:54.605729Z","shell.execute_reply":"2025-07-10T17:11:57.053621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_losses(gen_losses, disc_losses):\n    plt.figure(figsize=(10, 5))\n    plt.plot(gen_losses, label='Generator Loss')\n    plt.plot(disc_losses, label='Discriminator Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('GAN Training Losses')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\nplot_losses(g_loss, d_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T16:56:28.249776Z","iopub.execute_input":"2025-07-10T16:56:28.250084Z","iopub.status.idle":"2025-07-10T16:56:28.488477Z","shell.execute_reply.started":"2025-07-10T16:56:28.250055Z","shell.execute_reply":"2025-07-10T16:56:28.487767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compare_real_vs_fake(train_loader, generator, noise_dim, n_images):\n\n    # Get real images\n    real_images = next(iter(train_loader))[0][:n_images]\n    real_images = real_images.squeeze() \n\n    # Generate fake images\n    generator.eval()\n    with torch.no_grad():\n        noise = torch.randn(n_images, noise_dim).to(device)\n        fake_images = generator(noise).view(n_images, 28, 28)\n\n    # Plot comparison\n    fig, axes = plt.subplots(2, n_images, figsize=(12, 4))\n\n    for i in range(n_images):\n        # Real images\n        axes[0, i].imshow(real_images[i].cpu().numpy(), cmap='gray')\n        axes[0, i].set_title('Real' if i == 0 else '')\n        axes[0, i].axis('off')\n\n        # Fake images\n        axes[1, i].imshow(fake_images[i].cpu().numpy(), cmap='gray')\n        axes[1, i].set_title('Generated' if i == 0 else '')\n        axes[1, i].axis('off')\n\n    plt.tight_layout()\n    plt.show()\ncompare_real_vs_fake(train_loader, generator, Z_DIM, n_images = 10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T17:03:08.288818Z","iopub.execute_input":"2025-07-10T17:03:08.289071Z","iopub.status.idle":"2025-07-10T17:03:09.174495Z","shell.execute_reply.started":"2025-07-10T17:03:08.289054Z","shell.execute_reply":"2025-07-10T17:03:09.173770Z"}},"outputs":[],"execution_count":null}]}